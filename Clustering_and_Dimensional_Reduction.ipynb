{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bNepbxuvBNWi"
   },
   "source": [
    "# Homework 3: Due Sunday 11:59pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4M5d3VPpBNWm"
   },
   "source": [
    "In this assignment, we are working on a list of 1200 bitstrings, where each of them contains 16 bits. <br >\n",
    "We will apply Agglomerative Clustering, K-means Clustering, and PCA to this dataset. <br >\n",
    "\n",
    "## Background and Data Information\n",
    "For a bitstring $S$ in this dataset, we describe $S = \\{s_{15}, s_{14}, s_{13}, s_{12}, \\ldots, s_{0} \\}$, where $s_{15}$ is often known as the most significant bit (MSB) and $s_0$ as the least significant bit (LSB). <br >\n",
    "\n",
    "There are duplicated bitstrings in this dataset, but they will not affect this assignment. Don't worry about them. <br >\n",
    "\n",
    "## Equivalence Relation\n",
    "\n",
    "**This is an important concept to Exercise 1.**\n",
    "\n",
    "Let's say if we have two bitstrings, $A = \\{a_{15}, a_{14}, a_{13}, \\ldots, a_{0} \\}$ and $B = \\{b_{15}, b_{14}, b_{13}, \\ldots, b_{0} \\}$. <br >\n",
    "\n",
    "We can flip one bit $a_i$ in $A$ to get another bitstring $A'$, such that the difference of $A$ and $A'$ is only one bit. We define the above transformation to be $A \\to A'$. <br >\n",
    "\n",
    "\n",
    "We call two bitstrings $A$ and $B$ to be **equivalent** ($A \\sim B$) if there exists a sequence $A \\to C_1 \\to C_2 \\to \\cdots \\to C_n \\to B$, where $\\forall i, C_i$ belongs to the dataset.\n",
    "\n",
    "It can be seen that equivalence is both __commutative__ ($A \\sim B \\iff B \\sim A$) as well as __transitive__ ($A \\sim B, B \\sim C \\implies A \\sim C$). <br >\n",
    "\n",
    "We can say that the elements in the above sequence $\\{ A, C_1, \\ldots, C_n, B\\}$ form an equivalence class. Given a new bitstring $X$, we can see that if $X \\sim C_i$, $1 \\le i \\le n$, then $X$ will be added to the above equivalence class, and by the transitive property of equivalence relations, $X \\sim A$, and $X \\sim B$.\n",
    "\n",
    "### Example\n",
    "\n",
    "Let's say we have 4 bitstrings, each of them is 4 bits long. They are $0000, 0010, 0110, 1100$, respectively.<br >\n",
    "\n",
    "We can say $0000 \\sim 0110$ because $0000 \\to 0010 \\to 0110$. <br >\n",
    "\n",
    "However, $0000 \\nsim 1100$. There may be sequences like $0000 \\to 1000 \\to 1100$ or $0000 \\to 0100 \\to 1100$, but neither $1000$ nor $0100$ is in our dataset. <br >\n",
    "\n",
    "Ultimately, $\\{0000, 0010, 0110\\}$ form an equivalence class, whereas $\\{1100\\}$ is the other. As a result, there are two classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddqEVDQwBNWo"
   },
   "source": [
    "### Libraries that can be used: numpy, scipy, pandas, scikit-learn, matplotlib, seaborn\n",
    "Any libraries used in the discussion and lecture materials are also allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dca6xFznXOvX"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/ucsd-dse220-f25/hw3.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACCnVnK6BNWq"
   },
   "source": [
    "# Exercises\n",
    "## Exercise 1 - Agglomerative Clustering (20 points in total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XiKJO3a3BNWr"
   },
   "source": [
    "Using agglomerative clustering with a distance threshold for early stopping, we can calculate the number of equivalence classes by counting the number of clusters. In order to perform agglomerative clustering, we have to consider what parameters may be used: <br >\n",
    "\n",
    "### Exercise 1.1 - Choosing Parameters (5 points)\n",
    "\n",
    " - Explain why you would pick these parameters.\n",
    "     - Which linkage rule should be used? (single-linkage, complete-linkage, or average-linkage)\n",
    "     - Which distance function should be used? (Euclidean distance, Manhattan distance, or cosine distance)\n",
    "     - What should the threshold distance be?\n",
    "\n",
    "Hints:\n",
    " - How the distance threshold works: Whenever two clusters are picked to consider merging them, the distance between those clusters is compared to the distance threshold. If the distance is smaller than the threshold, the clusters merge and the algorithm continues; Otherwise, they will not be merged.\n",
    " - How to choose a linkage rule: Think about how you would figure out which equivalence class the string $0001$ belongs to in the previously given example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YbPKru-hBNWt"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./hw3/bitstrings.csv') # change filename location based on your setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUBeJllzBNWv"
   },
   "source": [
    "### Exercise 1.2 - Agglomerative Clustering for Equivalence Classes (15 points)\n",
    "\n",
    " - Perform the agglomerative clustering with the parameters you picked in the above three questions.\n",
    " - Show the frequency(number of members) of each cluster. You are encouraged to create a bar chart to show the distribution as it will help you in Exercise 2, but printing only the numbers is also fine.\n",
    "\n",
    "Hints:\n",
    " - The value of ```distance_threshold``` in the arguments should be **slightly** higher than what you picked. This is because we only merge two clusters when their distance is **strictly smaller** than the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yvnBbzDNBNWw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66TlQAHcBNWx"
   },
   "source": [
    "## Exercise 2 - K-Means Clustering (20 points in total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMeLd_zCBNWy"
   },
   "source": [
    "Let's see how k-means behave differently from agglomerative clustering.\n",
    "\n",
    "### Exercise 2.1 - K-Means Clustering for Equivalence Classes (10 points)\n",
    " - Re-cluster the dataset with k-means, but with the number of clusters you obtained from Exercise 1.\n",
    " - Show the frequency(number of members) of each cluster. Again, you are encouraged to create a bar chart, but printing the numbers is also fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vF7fX1xnBNW0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-wcTXfIBNW1"
   },
   "source": [
    "### Exercise 2.2 - Difference between Agglomerative Clustering and K-Means Clustering (10 points)\n",
    "\n",
    "Compare the result from Exercise 2.1 with that from Exercise 1.2, and explain\n",
    " - How the two results are different\n",
    " - Why there is such a difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ubqcYkvHBNW1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UZ7x7XLmBNW2"
   },
   "source": [
    "## Exercise 3 - Principal Component Analysis (30 points in total)\n",
    "\n",
    "We can visualize how the bitstrings are distributed using principal component analysis.\n",
    "\n",
    "### Exercise 3.1 - Generate 2 Clusters (10 points)\n",
    "\n",
    " - Re-do the k-means clustering on our dataset again, but this time we only consider ```k=2```.\n",
    " - Show the frequency(number of members) of each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JesfXSz2BNW2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oopLQZzNBNW3"
   },
   "source": [
    "### Exercise 3.2 - PCA for Feature Extraction (20 points)\n",
    "\n",
    " - Retrieve the projected dataset with PCA, using ```n_components=2```.\n",
    " - Generate a scatter plot to visualize the projected points, where they should be colored differently based on the assigned cluster in Exercise 3.1.\n",
    " - In the first principal component, **print out** the weights of all features.\n",
    " - Report which feature has the **highest positive** weight in the first principal component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3bBdEj7MBNW3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zub17AVhCtPj"
   },
   "source": [
    "## Exercise 4 - Singular Value Decomposition (30 points in total)\n",
    "\n",
    "Let's decompose our data set into left and right matrices to find unknown structure in our data\n",
    "\n",
    "### Exercise 4.1 - Generate the [SVD](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html) (10 points)\n",
    "\n",
    " - Generate multiple SVD's using 2, 3 and 4 components ```k=2, k=3 and k=4```.\n",
    " Give each SVD it's own python variable.\n",
    " - Calculate a pairwise cosine similarity of our kxn matrix for n features (should result in an nxn matrix)\n",
    " - Generate Pair plots for the left and right matrices.\n",
    " - Evaluate your results and what can you extract from the results of k=2, k=3 and k=4 dimensional reductions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OcIaot2GP-G4"
   },
   "source": [
    "**Before performing SVD, let's first calculate our Eigen values and Eigen vectors of our matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0VgCTjBuQGdS"
   },
   "outputs": [],
   "source": [
    "eigen_values, eigen_vectors = np.linalg.eig(np.array(df).T @ np.array(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-tFdAHFdQIsO"
   },
   "outputs": [],
   "source": [
    "# Let's evaluate our values. You can use this for your final evaluation for 4.1\n",
    "eigen_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TzCu8XLJCv1C"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4a9fR-unDbYf"
   },
   "outputs": [],
   "source": [
    "# Here we generate an SVD using k = 5 yielding u,s,v of mx5, 5x5, nx5.T\n",
    "svd = TruncatedSVD(n_components=5, n_iter=1000, random_state=76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x7nzG00ZDbi8"
   },
   "outputs": [],
   "source": [
    "svd.fit(df)\n",
    "print(svd.explained_variance_ratio_) # Prints the explained variance for each of the 5 components\n",
    "print(svd.explained_variance_ratio_.sum()) # Prints the sum of the 5 from above\n",
    "sigma_matrix = np.diag(svd.singular_values_) # Creates the sigma matrix from the singular values\n",
    "print(sigma_matrix) # Prints the sigma matrix\n",
    "singular_vals = svd.singular_values_ # Our singular values\n",
    "print(singular_vals) # Prints singular values as a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MU3qhOwCPVR0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D6_yd-VMFoxU"
   },
   "outputs": [],
   "source": [
    "# We will define our cosine similarity function\n",
    "def cosine_similarity(a, b):\n",
    "    \"\"\"Calculates the cosine similarity between two vectors.\"\"\"\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    return dot_product / (norm_a * norm_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1LEQZPtdFamT"
   },
   "outputs": [],
   "source": [
    "right_matrix = pd.DataFrame(svd.components_)\n",
    "right_matrix.shape # lets check the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KOfJ3OjdFb7_"
   },
   "outputs": [],
   "source": [
    "right_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZRjovvAKVIL"
   },
   "source": [
    "**Generate code for performing a pairwise calculation of our features using cosine_similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4nXiav9zLRh4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prkZ-Ue7MTHh"
   },
   "source": [
    "**Let's extract our left matrix** This is similar to looking at customers with similar movie viewing habits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HLFuw5xkF8Vg"
   },
   "outputs": [],
   "source": [
    "left_matrix = pd.DataFrame(svd.fit_transform(df))/singular_vals\n",
    "left_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "39-RT9IEF9A2"
   },
   "outputs": [],
   "source": [
    "left_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AgbrvV9fRHMt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uf4hhMBuJY0R"
   },
   "source": [
    "**Explain your interpretation for each of the SVD's you generated for k=2, 3, 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWZKTM52JhTH"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohRnp0xBCvf5"
   },
   "source": [
    "### Exercise 4.2 - Generate Clusters (10 points)\n",
    "\n",
    " - Re-do the k-means clustering on our dataset again for the three different components created by you above, of the left matrix.\n",
    " - Show the frequency (number of members) of each cluster.\n",
    " - Generate clusters from 2 to 10\n",
    " - Use the [silhouette](https://scikit-learn.org/1.5/auto_examples/cluster/plot_kmeans_silhouette_analysis.html) method to choose the best k clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PGHYoIckCv_G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FcwzW-FoCwFZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m9vFxokzBNW4"
   },
   "source": [
    "## Exercise 4 - Collaborative Statement (5 points)\n",
    "### You must fill this out even if you worked alone to get credit.\n",
    "\n",
    "It is mandatory to include a Statement of Collaboration in each submission, that follows the guidelines below.\n",
    "Include the names of everyone involved in the discussions (especially in-person ones), and what was discussed.\n",
    "All students are required to follow the academic honesty guidelines posted on the course website. For\n",
    "programming assignments in particular, I encourage students to organize (perhaps using Piazza) to discuss the\n",
    "task descriptions, requirements, possible bugs in the support code, and the relevant technical content before they\n",
    "start working on it. However, you should not discuss the specific solutions, and as a guiding principle, you are\n",
    "not allowed to take anything written or drawn away from these discussions (no photographs of the blackboard,\n",
    "written notes, referring to Piazza, etc.). Especially after you have started working on the assignment, try to restrict\n",
    "the discussion to Piazza as much as possible, so that there is no doubt as to the extent of your collaboration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wOxdJZGjBNW4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
